{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92aaf5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518396</th>\n",
       "      <td>5</td>\n",
       "      <td>Will not do without</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518397</th>\n",
       "      <td>2</td>\n",
       "      <td>disappointed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518398</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518399</th>\n",
       "      <td>5</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518400</th>\n",
       "      <td>5</td>\n",
       "      <td>Great Honey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Score                             Summary\n",
       "518396      5                 Will not do without\n",
       "518397      2                        disappointed\n",
       "518398      5            Perfect for our maltipoo\n",
       "518399      5  Favorite Training and reward treat\n",
       "518400      5                         Great Honey"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing Pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Load Data\n",
    "df = pd.read_csv('imbalanced_updated.csv')    \n",
    "\n",
    "#View Data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a04dbf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\n",
      "1     46545\n",
      "2     25588\n",
      "3     37557\n",
      "4     73008\n",
      "5    335703\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "score_counts = df['Score'].value_counts().sort_index()\n",
    "\n",
    "print(score_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b78ab6",
   "metadata": {},
   "source": [
    "Text Normalization Code (Clean & Commented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1f9d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91940\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91940\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\91940\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91940\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\91940\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining samples after cleaning: 263842\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>cleaned_summary</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Be careful ordering fragile items online!</td>\n",
       "      <td>careful ordering fragile item online</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>love love love</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Truly Tasty Granola Bars and Bags of Granola</td>\n",
       "      <td>truly tasty granola bar bag granola</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GREAT GF food</td>\n",
       "      <td>great gf food</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Great Granola Bars</td>\n",
       "      <td>great granola bar</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Summary  \\\n",
       "1      Be careful ordering fragile items online!   \n",
       "4                                 LOVE LOVE LOVE   \n",
       "7   Truly Tasty Granola Bars and Bags of Granola   \n",
       "9                                  GREAT GF food   \n",
       "11                            Great Granola Bars   \n",
       "\n",
       "                         cleaned_summary  Score  \n",
       "1   careful ordering fragile item online      3  \n",
       "4                         love love love      5  \n",
       "7    truly tasty granola bar bag granola      5  \n",
       "9                          great gf food      5  \n",
       "11                     great granola bar      4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required NLTK resources (only first time)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean and normalize text\n",
    "def clean_text(text):\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove URLs and HTML tags\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)   # URLs\n",
    "    text = re.sub(r'<.*?>', '', text)                    # HTML\n",
    "    \n",
    "    # 3. Remove emojis and non-alphabetic characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)                  # punctuation\n",
    "    text = re.sub(r'[\\d_]', '', text)                    # numbers and underscores\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()             # extra spaces\n",
    "    \n",
    "    # 4. Tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # 5. Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # 6. Lemmatize (convert words to base form)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # 7. Rejoin tokens\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply cleaning to your dataset\n",
    "df['cleaned_summary'] = df['Summary'].astype(str).apply(clean_text)\n",
    "\n",
    "# 8. Filter out reviews with <3 words or extremely long text (>150 words)\n",
    "df = df[df['cleaned_summary'].apply(lambda x: len(x.split()) >= 3)]\n",
    "df = df[df['cleaned_summary'].apply(lambda x: len(x.split()) <= 150)]\n",
    "\n",
    "print(\"Remaining samples after cleaning:\", len(df))\n",
    "df[['Summary', 'cleaned_summary', 'Score']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60bb28e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     careful ordering fragile item online\n",
      "4                           love love love\n",
      "7      truly tasty granola bar bag granola\n",
      "9                            great gf food\n",
      "11                       great granola bar\n",
      "Name: cleaned_summary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['cleaned_summary'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aacdab8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\n",
      "1     22246\n",
      "2     12432\n",
      "3     19818\n",
      "4     40787\n",
      "5    168559\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count how many reviews per score (1‚Äì5)\n",
    "score_counts = df['Score'].value_counts().sort_index()\n",
    "\n",
    "print(score_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f9e938",
   "metadata": {},
   "source": [
    "we take 20,000 total sample reviews for imbalanced training. with 1 star with 10% , 2 satr with 15%, 3 star with 25%, 4 star with 30% and 5 star with 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135d0d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining samples after cleaning: 263842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Score\n",
       "1    2000\n",
       "2    3000\n",
       "3    5000\n",
       "4    6000\n",
       "5    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# (your cleaning code as before)\n",
    "df['cleaned_summary'] = df['Summary'].astype(str).apply(clean_text)\n",
    "df = df[df['cleaned_summary'].apply(lambda x: len(x.split()) >= 3)]\n",
    "df = df[df['cleaned_summary'].apply(lambda x: len(x.split()) <= 150)]\n",
    "\n",
    "print(\"Remaining samples after cleaning:\", len(df))\n",
    "\n",
    "# --- SAMPLING FROM CLEANED DATA ---\n",
    "sample_sizes = {\n",
    "    1: 2000,\n",
    "    2: 3000,\n",
    "    3: 5000,\n",
    "    4: 6000,\n",
    "    5: 4000\n",
    "}\n",
    "\n",
    "sampled_parts = []\n",
    "for score, n in sample_sizes.items():\n",
    "    subset = df[df['Score'] == score].sample(n=n, random_state=42)\n",
    "    sampled_parts.append(subset)\n",
    "\n",
    "sampled_df = pd.concat(sampled_parts, ignore_index=True)\n",
    "sampled_df = sampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Optional: view counts\n",
    "sampled_df['Score'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1522d8",
   "metadata": {},
   "source": [
    "SAVE THE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6438a77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File saved successfully as: the_real_imbalanced.csv\n"
     ]
    }
   ],
   "source": [
    "# --- SAVE THE FILE ---\n",
    "output_path = \"the_real_imbalanced.csv\"\n",
    "sampled_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"‚úÖ File saved successfully as: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8124e83d",
   "metadata": {},
   "source": [
    "test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aff6e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 20000\n",
      "\n",
      "Class distribution:\n",
      "Score\n",
      "1    2000\n",
      "2    3000\n",
      "3    5000\n",
      "4    6000\n",
      "5    4000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Split Summary ---\n",
      "Training set size: 16000 (80.0%)\n",
      "Test set size: 4000 (20.0%)\n",
      "\n",
      "Training set distribution:\n",
      "Score\n",
      "1    1600\n",
      "2    2400\n",
      "3    4000\n",
      "4    4800\n",
      "5    3200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set distribution:\n",
      "Score\n",
      "1     400\n",
      "2     600\n",
      "3    1000\n",
      "4    1200\n",
      "5     800\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ Files saved successfully:\n",
      "   - train_data.csv\n",
      "   - test_data.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the cleaned and sampled data\n",
    "sampled_df = pd.read_csv(\"the_real_imbalanced.csv\")\n",
    "\n",
    "# Verify the data\n",
    "print(\"Total samples:\", len(sampled_df))\n",
    "print(\"\\nClass distribution:\")\n",
    "print(sampled_df['Score'].value_counts().sort_index())\n",
    "\n",
    "# Perform 80:20 train-test split with stratification\n",
    "# stratify ensures each split maintains the same class distribution\n",
    "X = sampled_df['cleaned_summary']\n",
    "y = sampled_df['Score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,           # 20% for testing\n",
    "    random_state=42,         # for reproducibility\n",
    "    stratify=y               # maintains class balance in both splits\n",
    ")\n",
    "\n",
    "# Create train and test dataframes\n",
    "train_df = pd.DataFrame({\n",
    "    'cleaned_summary': X_train,\n",
    "    'Score': y_train\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'cleaned_summary': X_test,\n",
    "    'Score': y_test\n",
    "})\n",
    "\n",
    "# Display split information\n",
    "print(\"\\n--- Split Summary ---\")\n",
    "print(f\"Training set size: {len(train_df)} ({len(train_df)/len(sampled_df)*100:.1f}%)\")\n",
    "print(f\"Test set size: {len(test_df)} ({len(test_df)/len(sampled_df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nTraining set distribution:\")\n",
    "print(train_df['Score'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nTest set distribution:\")\n",
    "print(test_df['Score'].value_counts().sort_index())\n",
    "\n",
    "# Save the splits to separate CSV files\n",
    "train_df.to_csv(\"train_data.csv\", index=False, encoding='utf-8')\n",
    "test_df.to_csv(\"test_data.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(\"\\n‚úÖ Files saved successfully:\")\n",
    "print(\"   - train_data.csv\")\n",
    "print(\"   - test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d0c812",
   "metadata": {},
   "source": [
    "training onn best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a73ed636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 16000\n",
      "Test set size: 4000\n",
      "\n",
      "============================================================\n",
      "\n",
      "üîÑ Converting text to TF-IDF features...\n",
      "‚úÖ Feature matrix shape: (16000, 5000)\n",
      "============================================================\n",
      "\n",
      "üîÑ Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91940\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Logistic Regression - Accuracy: 0.4377 | Time: 2.49s\n",
      "\n",
      "üîÑ Training Random Forest...\n",
      "‚úÖ Random Forest - Accuracy: 0.4828 | Time: 9.57s\n",
      "\n",
      "üîÑ Training Linear SVM...\n",
      "‚úÖ Linear SVM - Accuracy: 0.4425 | Time: 0.46s\n",
      "\n",
      "============================================================\n",
      "üìä MODEL COMPARISON\n",
      "============================================================\n",
      "              Model  Accuracy  Training Time (s)\n",
      "      Random Forest   0.48275           9.566001\n",
      "         Linear SVM   0.44250           0.462611\n",
      "Logistic Regression   0.43775           2.486049\n",
      "\n",
      "üèÜ BEST MODEL: Random Forest (Accuracy: 0.4828)\n",
      "\n",
      "============================================================\n",
      "üìà DETAILED EVALUATION - Random Forest\n",
      "============================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Score 1       0.44      0.38      0.41       400\n",
      "     Score 2       0.50      0.34      0.40       600\n",
      "     Score 3       0.47      0.48      0.47      1000\n",
      "     Score 4       0.50      0.59      0.54      1200\n",
      "     Score 5       0.48      0.48      0.48       800\n",
      "\n",
      "    accuracy                           0.48      4000\n",
      "   macro avg       0.48      0.45      0.46      4000\n",
      "weighted avg       0.48      0.48      0.48      4000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "        Pred 1  Pred 2  Pred 3  Pred 4  Pred 5\n",
      "True 1     152      54      99      56      39\n",
      "True 2      76     203     160     105      56\n",
      "True 3      56      77     481     278     108\n",
      "True 4      34      47     194     707     218\n",
      "True 5      27      26      95     264     388\n",
      "\n",
      "============================================================\n",
      "üíæ SAVING BEST MODEL\n",
      "============================================================\n",
      "‚úÖ Model saved as: best_model_random_forest.pkl\n",
      "‚úÖ Vectorizer saved as: tfidf_vectorizer.pkl\n",
      "\n",
      "============================================================\n",
      "‚ú® TRAINING COMPLETE!\n",
      "\n",
      "üèÜ MODEL B: Random Forest (Accuracy: 0.4828)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# Load train and test data\n",
    "train_df = pd.read_csv(\"train_data.csv\")\n",
    "test_df = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "X_train = train_df['cleaned_summary']\n",
    "y_train = train_df['Score']\n",
    "X_test = test_df['cleaned_summary']\n",
    "y_test = test_df['Score']\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# STEP 1: VECTORIZATION\n",
    "# ============================================\n",
    "print(\"\\nüîÑ Converting text to TF-IDF features...\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,      # limit to top 5000 features\n",
    "    ngram_range=(1, 2),     # unigrams and bigrams\n",
    "    min_df=2,               # ignore terms that appear in less than 2 documents\n",
    "    max_df=0.8              # ignore terms that appear in more than 80% of documents\n",
    ")\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"‚úÖ Feature matrix shape: {X_train_tfidf.shape}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# STEP 2: TRAIN MODELS\n",
    "# ============================================\n",
    "\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# --- Logistic Regression ---\n",
    "print(\"\\nüîÑ Training Logistic Regression...\")\n",
    "start_time = time.time()\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    solver='lbfgs',\n",
    "    multi_class='multinomial',\n",
    "    class_weight='balanced'  # handles class imbalance\n",
    ")\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "lr_pred = lr_model.predict(X_test_tfidf)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "lr_time = time.time() - start_time\n",
    "\n",
    "models['Logistic Regression'] = lr_model\n",
    "results['Logistic Regression'] = {\n",
    "    'accuracy': lr_accuracy,\n",
    "    'predictions': lr_pred,\n",
    "    'training_time': lr_time\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Logistic Regression - Accuracy: {lr_accuracy:.4f} | Time: {lr_time:.2f}s\")\n",
    "\n",
    "# --- Random Forest ---\n",
    "print(\"\\nüîÑ Training Random Forest...\")\n",
    "start_time = time.time()\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # use all CPU cores\n",
    "    class_weight='balanced'\n",
    ")\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "rf_pred = rf_model.predict(X_test_tfidf)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "rf_time = time.time() - start_time\n",
    "\n",
    "models['Random Forest'] = rf_model\n",
    "results['Random Forest'] = {\n",
    "    'accuracy': rf_accuracy,\n",
    "    'predictions': rf_pred,\n",
    "    'training_time': rf_time\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Random Forest - Accuracy: {rf_accuracy:.4f} | Time: {rf_time:.2f}s\")\n",
    "\n",
    "# --- Linear SVM ---\n",
    "print(\"\\nüîÑ Training Linear SVM...\")\n",
    "start_time = time.time()\n",
    "\n",
    "svm_model = LinearSVC(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "svm_pred = svm_model.predict(X_test_tfidf)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "svm_time = time.time() - start_time\n",
    "\n",
    "models['Linear SVM'] = svm_model\n",
    "results['Linear SVM'] = {\n",
    "    'accuracy': svm_accuracy,\n",
    "    'predictions': svm_pred,\n",
    "    'training_time': svm_time\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Linear SVM - Accuracy: {svm_accuracy:.4f} | Time: {svm_time:.2f}s\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 3: COMPARE MODELS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[m]['accuracy'] for m in results.keys()],\n",
    "    'Training Time (s)': [results[m]['training_time'] for m in results.keys()]\n",
    "})\n",
    "comparison_df = comparison_df.sort_values('Accuracy', ascending=False)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "best_accuracy = comparison_df.iloc[0]['Accuracy']\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name} (Accuracy: {best_accuracy:.4f})\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 4: DETAILED EVALUATION OF BEST MODEL\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"üìà DETAILED EVALUATION - {best_model_name}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, best_predictions, target_names=[f\"Score {i}\" for i in range(1, 6)]))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=[f\"True {i}\" for i in range(1, 6)],\n",
    "                     columns=[f\"Pred {i}\" for i in range(1, 6)])\n",
    "print(cm_df)\n",
    "\n",
    "# ============================================\n",
    "# STEP 5: SAVE BEST MODEL AND VECTORIZER\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üíæ SAVING BEST MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save the best model\n",
    "model_filename = f\"best_model_{best_model_name.replace(' ', '_').lower()}.pkl\"\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"‚úÖ Model saved as: {model_filename}\")\n",
    "\n",
    "# Save the vectorizer (IMPORTANT - needed for making predictions on new data)\n",
    "vectorizer_filename = \"tfidf_vectorizer.pkl\"\n",
    "joblib.dump(vectorizer, vectorizer_filename)\n",
    "print(f\"‚úÖ Vectorizer saved as: {vectorizer_filename}\")\n",
    "\n",
    "# Save results summary\n",
    "summary = {\n",
    "    'best_model': best_model_name,\n",
    "    'accuracy': float(best_accuracy),\n",
    "    'all_results': {k: {'accuracy': float(v['accuracy']), \n",
    "                        'training_time': float(v['training_time'])} \n",
    "                    for k, v in results.items()}\n",
    "}\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚ú® TRAINING COMPLETE!\")\n",
    "print(f\"\\nüèÜ MODEL B: {best_model_name} (Accuracy: {best_accuracy:.4f})\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f6e35",
   "metadata": {},
   "source": [
    "test of model A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cd55807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Checking: ../../Models/Model_A_linear_svm.pkl\n",
      "\n",
      "üìÅ Checking: ../../Models/Model_A_vectorizer.pkl\n",
      "\n",
      "üîÑ Loading model...\n",
      "UnpicklingError: invalid load key, '\\x0b'.\n",
      "\n",
      "üîÑ Loading vectorizer...\n",
      "UnpicklingError: invalid load key, '\\x07'.\n",
      "\n",
      "============================================================\n",
      "‚úÖ MODEL A TEST DATA\n",
      "============================================================\n",
      "\n",
      "Loading test data...\n",
      "Test set size: 4000 samples\n",
      "\n",
      "Class distribution in test set:\n",
      "Score\n",
      "1     400\n",
      "2     600\n",
      "3    1000\n",
      "4    1200\n",
      "5     800\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Vectorizing test data...\n",
      "Feature matrix shape: (4000, 5000)\n",
      "\n",
      "Making predictions...\n",
      "\n",
      "============================================================\n",
      "MODEL A TEST ACCURACY RESULTS\n",
      "============================================================\n",
      "\n",
      "Overall Metrics:\n",
      "  Accuracy:          0.4000 (40.00%)\n",
      "  Weighted F1-Score: 0.3996\n",
      "  Macro F1-Score:    0.3968\n",
      "  Precision:         0.4120\n",
      "  Recall:            0.4000\n",
      "\n",
      "------------------------------------------------------------\n",
      "Detailed Classification Report:\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Score 1       0.32      0.55      0.40       400\n",
      "     Score 2       0.32      0.37      0.34       600\n",
      "     Score 3       0.41      0.32      0.36      1000\n",
      "     Score 4       0.48      0.38      0.42      1200\n",
      "     Score 5       0.43      0.48      0.45       800\n",
      "\n",
      "    accuracy                           0.40      4000\n",
      "   macro avg       0.39      0.42      0.40      4000\n",
      "weighted avg       0.41      0.40      0.40      4000\n",
      "\n",
      "\n",
      "============================================================\n",
      "PER-CLASS PERFORMANCE\n",
      "============================================================\n",
      " Score  Count  Correct  Accuracy\n",
      "     1    400      218  0.545000\n",
      "     2    600      221  0.368333\n",
      "     3   1000      323  0.323000\n",
      "     4   1200      455  0.379167\n",
      "     5    800      383  0.478750\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "model_path = '../../Models/Model_A_linear_svm.pkl'\n",
    "vectorizer_path = '../../Models/Model_A_vectorizer.pkl'\n",
    "\n",
    "def diagnose_pickle_file(file_path):\n",
    "    \n",
    "    print(f\"\\nüìÅ Checking: {file_path}\")\n",
    "    \n",
    "    \n",
    "# Diagnose both files\n",
    "model_valid = diagnose_pickle_file(model_path)\n",
    "vectorizer_valid = diagnose_pickle_file(vectorizer_path)\n",
    "\n",
    "\n",
    "\n",
    "def safe_pickle_load(file_path, description):\n",
    "    \n",
    "    print(f\"\\nüîÑ Loading {description}...\")\n",
    "    \n",
    "    # Method 1: Standard pickle load\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            obj = pickle.load(f)\n",
    "       \n",
    "        return obj, True\n",
    "    except Exception as e:\n",
    "        print(f\"{type(e).__name__}: {e}\")\n",
    "    \n",
    "    # Method 2: Try different pickle protocols\n",
    "    for protocol in range(6):\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                obj = pickle.load(f, encoding='latin1')\n",
    "           \n",
    "            return obj, True\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Method 3: Check if it's a joblib file instead\n",
    "    try:\n",
    "        import joblib\n",
    "        obj = joblib.load(file_path)\n",
    "       \n",
    "        return obj, True\n",
    "    except Exception as e:\n",
    "        print(f\" {type(e).__name__}\")\n",
    "    \n",
    "    print(f\" {description}\")\n",
    "    return None, False\n",
    "\n",
    "# Try to load model\n",
    "model, model_loaded = safe_pickle_load(model_path, \"model\")\n",
    "\n",
    "# Try to load vectorizer\n",
    "vectorizer, vectorizer_loaded = safe_pickle_load(vectorizer_path, \"vectorizer\")\n",
    "\n",
    "# --- PROCEED WITH EVALUATION IF FILES LOADED ---\n",
    "if model_loaded and vectorizer_loaded:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ MODEL A TEST DATA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # --- LOAD TEST DATA ---\n",
    "    print(\"\\nLoading test data...\")\n",
    "    test_df = pd.read_csv(\"test_data.csv\")\n",
    "    X_test = test_df['cleaned_summary']\n",
    "    y_test = test_df['Score']\n",
    "    \n",
    "    print(f\"Test set size: {len(test_df)} samples\")\n",
    "    print(f\"\\nClass distribution in test set:\")\n",
    "    print(y_test.value_counts().sort_index())\n",
    "    \n",
    "    # --- VECTORIZE TEST DATA ---\n",
    "    print(\"\\nVectorizing test data...\")\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    print(f\"Feature matrix shape: {X_test_vec.shape}\")\n",
    "    \n",
    "    # --- MAKE PREDICTIONS ---\n",
    "    print(\"\\nMaking predictions...\")\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    \n",
    "    # --- CALCULATE METRICS ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL A TEST ACCURACY RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"\\nOverall Metrics:\")\n",
    "    print(f\"  Accuracy:          {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"  Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "    print(f\"  Macro F1-Score:    {f1_macro:.4f}\")\n",
    "    print(f\"  Precision:         {precision:.4f}\")\n",
    "    print(f\"  Recall:            {recall:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"Detailed Classification Report:\")\n",
    "    print(\"-\"*60)\n",
    "    print(classification_report(y_test, y_pred, target_names=[f'Score {i}' for i in range(1, 6)]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # --- PER-CLASS ANALYSIS ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PER-CLASS PERFORMANCE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    per_class_results = []\n",
    "    for i in range(1, 6):\n",
    "        mask = y_test == i\n",
    "        if mask.sum() > 0:\n",
    "            class_accuracy = (y_pred[mask] == i).sum() / mask.sum()\n",
    "            per_class_results.append({\n",
    "                'Score': i,\n",
    "                'Count': mask.sum(),\n",
    "                'Correct': (y_pred[mask] == i).sum(),\n",
    "                'Accuracy': class_accuracy\n",
    "            })\n",
    "    \n",
    "    per_class_df = pd.DataFrame(per_class_results)\n",
    "    print(per_class_df.to_string(index=False))\n",
    "    \n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚ùå CANNOT PROCEED - FILES FAILED TO LOAD\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nüîß TROUBLESHOOTING SUGGESTIONS:\")\n",
    "    print(\"\\n1. Check if files were saved with joblib instead of pickle:\")\n",
    "    print(\"   Try: import joblib; model = joblib.load('model_path')\")\n",
    "    print(\"\\n2. Verify the model was saved correctly during training\")\n",
    "    print(\"\\n3. Check if the file path is correct\")\n",
    "    print(\"\\n4. Ensure the files aren't corrupted (check file sizes)\")\n",
    "    print(\"\\n5. If files were created on different OS/Python version, try:\")\n",
    "    print(\"   pickle.load(f, encoding='latin1')\")\n",
    "    print(\"\\n6. Re-train and save the model if files are corrupted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b945f71d",
   "metadata": {},
   "source": [
    "Import Visualization Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d85adeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Optional: Set a clean visual style\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"pastel\", font_scale=1.1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a4f92",
   "metadata": {},
   "source": [
    "Bar Plot ‚Äî Review Count per Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b514321f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91940\\AppData\\Local\\Temp\\ipykernel_20316\\2137379531.py:6: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(data=sampled_df, x='Score', palette='viridis', edgecolor='black')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example visualization\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=sampled_df, x='Score', palette='viridis', edgecolor='black')\n",
    "plt.title('Sampled Dataset: 20K Reviews by Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a922c2f",
   "metadata": {},
   "source": [
    "Display 3‚Äì10 Sample Reviews per Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b143c24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "‚≠ê Rating: 1\n",
      "========================================\n",
      "1. inferior quality goji berry\n",
      "\n",
      "2. even good rat bait\n",
      "\n",
      "3. rainbow match photo whatsoever\n",
      "\n",
      "4. new formula ingredient match amazon description\n",
      "\n",
      "5. there hole bagwatch\n",
      "\n",
      "\n",
      "========================================\n",
      "‚≠ê Rating: 2\n",
      "========================================\n",
      "1. like lowcarb snack\n",
      "\n",
      "2. might good smaller dog large one\n",
      "\n",
      "3. dent like road kill\n",
      "\n",
      "4. much smaller expected\n",
      "\n",
      "5. may work squirrel absolutely chipmunk\n",
      "\n",
      "\n",
      "========================================\n",
      "‚≠ê Rating: 3\n",
      "========================================\n",
      "1. mccormick beware updated review\n",
      "\n",
      "2. nice aroma lacking bit vanilla flavour\n",
      "\n",
      "3. good taste high sucrose content\n",
      "\n",
      "4. salty good kick\n",
      "\n",
      "5. good coffee bean little stale\n",
      "\n",
      "\n",
      "========================================\n",
      "‚≠ê Rating: 4\n",
      "========================================\n",
      "1. yummmmm banana laffy taffy\n",
      "\n",
      "2. like chocolatecovered cherry\n",
      "\n",
      "3. nice smooth espresso\n",
      "\n",
      "4. dog love ita little pricey\n",
      "\n",
      "5. woof woof grrrr grrrrrrr yummm mmmmmmm\n",
      "\n",
      "\n",
      "========================================\n",
      "‚≠ê Rating: 5\n",
      "========================================\n",
      "1. best product best price\n",
      "\n",
      "2. best dog treat\n",
      "\n",
      "3. keep bottle handalways\n",
      "\n",
      "4. perfect base making puttanesca\n",
      "\n",
      "5. found chewing gum amazoncom\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display random sample reviews for each rating\n",
    "for rating in sorted(df['Score'].unique()):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"‚≠ê Rating: {rating}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    samples = df[df['Score'] == rating].sample(n=min(5, len(df[df['Score'] == rating])), random_state=42)\n",
    "    for i, review in enumerate(samples['cleaned_summary'], 1):\n",
    "        print(f\"{i}. {review}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987be6e7",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9acd645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "IMPROVED SENTIMENT ANALYSIS TRAINING PIPELINE\n",
      "======================================================================\n",
      "\n",
      "üìÇ Loading training dataset...\n",
      "Total available samples: 518401\n",
      "\n",
      "üìù Preprocessing ALL data first...\n",
      "Before filtering: 518401 samples\n",
      "After filtering: 466963 samples\n",
      "\n",
      "Class distribution after filtering:\n",
      "Score\n",
      "1     40669\n",
      "2     23185\n",
      "3     35148\n",
      "4     68032\n",
      "5    299929\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Creating training dataset with improved sampling...\n",
      "  Class 1: Sampled 3000 from 3000 available\n",
      "  Class 2: Sampled 3500 from 3500 available\n",
      "  Class 3: Sampled 4500 from 4500 available\n",
      "  Class 4: Sampled 5000 from 5000 available\n",
      "  Class 5: Sampled 4000 from 4000 available\n",
      "\n",
      "üìä Final training distribution:\n",
      "Score\n",
      "1    3000\n",
      "2    3500\n",
      "3    4500\n",
      "4    5000\n",
      "5    4000\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Total training samples: 20000\n",
      "\n",
      "üîß Extracting enhanced features...\n",
      "  Extracted 26 features\n",
      "\n",
      "üî§ Vectorizing text with improved parameters...\n",
      "üîó Combining features...\n",
      "Training feature shape: (20000, 5564)\n",
      "\n",
      "‚öñÔ∏è  Calculating optimized class weights...\n",
      "Smoothed class weights:\n",
      "  Class 1: 1.067 (n=3000)\n",
      "  Class 2: 1.067 (n=3500)\n",
      "  Class 3: 0.889 (n=4500)\n",
      "  Class 4: 0.800 (n=5000)\n",
      "  Class 5: 1.000 (n=4000)\n",
      "\n",
      "======================================================================\n",
      "TRAINING IMPROVED MODELS\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£  Training Logistic Regression (optimized)...\n",
      "   Performing cross-validation...\n",
      "   CV Macro F1: 0.4782 (+/- 0.0048)\n",
      "\n",
      "2Ô∏è‚É£  Training Calibrated LR...\n",
      "   Fitting calibrated model...\n",
      "   Performing cross-validation...\n",
      "   CV Macro F1: 0.4766 (+/- 0.0058)\n",
      "\n",
      "3Ô∏è‚É£  Training Random Forest (optimized)...\n",
      "   Performing cross-validation...\n",
      "   CV Macro F1: 0.4278 (+/- 0.0057)\n",
      "   OOB Score: 0.4269\n",
      "\n",
      "4Ô∏è‚É£  Training Gradient Boosting (NEW)...\n",
      "   Performing cross-validation...\n",
      "   CV Macro F1: 0.4704 (+/- 0.0048)\n",
      "\n",
      "======================================================================\n",
      "MODEL SELECTION\n",
      "======================================================================\n",
      "\n",
      "Model                     CV Macro F1     Std Dev   \n",
      "--------------------------------------------------\n",
      "lr_optimized              0.4782          0.0048    \n",
      "lr_calibrated             0.4766          0.0058    \n",
      "rf_optimized              0.4278          0.0057    \n",
      "gradient_boosting         0.4704          0.0048    \n",
      "\n",
      " Model_B: lr_optimized\n",
      "   CV Macro F1: 0.4782\n",
      "   Training Accuracy: 0.6260\n",
      "   Training Macro F1: 0.6277\n",
      "\n",
      "======================================================================\n",
      "SAVING MODEL AND ARTIFACTS\n",
      "======================================================================\n",
      "‚úÖ model_B.pkl\n",
      "‚úÖ model_B_vectorizer.pkl\n",
      "‚úÖ model_B_scaler.pkl\n",
      "‚úÖ model_B_metadata.pkl\n",
      "\n",
      "======================================================================\n",
      "‚ú® TRAINING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üìä Summary:\n",
      "   ‚Ä¢ Model: lr_optimized\n",
      "   ‚Ä¢ Training samples: 20000\n",
      "   ‚Ä¢ Features: 5564\n",
      "   ‚Ä¢ Training Accuracy: 0.6260\n",
      "   ‚Ä¢ Training Macro F1: 0.6277\n",
      "   ‚Ä¢ CV Macro F1: 0.4782 (+/- 0.0048)\n",
      "\n",
      "‚û°Ô∏è  Next: Run test_model.py with your test dataset\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# SCRIPT 1: IMPROVED TRAINING PIPELINE\n",
    "# File: train_model.py\n",
    "# ========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             accuracy_score, f1_score, make_scorer)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scipy.sparse import hstack\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"IMPROVED SENTIMENT ANALYSIS TRAINING PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ========================================\n",
    "# ENHANCED PREPROCESSING\n",
    "# ========================================\n",
    "def advanced_text_cleaning(text):\n",
    "    \"\"\"Enhanced text cleaning with better negation handling\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Preserve negations more aggressively\n",
    "    negation_words = ['not', 'no', 'never', 'neither', 'nobody', 'nothing', \n",
    "                      'nowhere', 'none', \"n't\", 'dont', 'wont', 'cant', 'shouldnt']\n",
    "    for word in negation_words:\n",
    "        text = re.sub(rf'\\b{word}\\b', f'NOT_{word}', text)\n",
    "    \n",
    "    # Preserve important contrasts\n",
    "    text = text.replace(' but ', ' BUT_CONTRAST ')\n",
    "    text = text.replace(' however ', ' HOWEVER_CONTRAST ')\n",
    "    text = text.replace(' although ', ' ALTHOUGH_CONTRAST ')\n",
    "    \n",
    "    # Remove noise\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s!?._]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_enhanced_features(df, text_column):\n",
    "    \"\"\"Enhanced feature extraction\"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Basic features\n",
    "    features['text_length'] = df[text_column].str.len()\n",
    "    features['word_count'] = df[text_column].str.split().str.len()\n",
    "    features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1)\n",
    "    features['unique_word_ratio'] = df[text_column].apply(\n",
    "        lambda x: len(set(str(x).split())) / (len(str(x).split()) + 1)\n",
    "    )\n",
    "    \n",
    "    # Punctuation & emphasis\n",
    "    features['exclamation_count'] = df[text_column].str.count(r'!')\n",
    "    features['question_count'] = df[text_column].str.count(r'\\?')\n",
    "    features['period_count'] = df[text_column].str.count(r'\\.')\n",
    "    features['uppercase_ratio'] = df[text_column].str.count(r'[A-Z]') / (features['text_length'] + 1)\n",
    "    features['all_caps_words'] = df[text_column].apply(\n",
    "        lambda x: sum(1 for word in str(x).split() if word.isupper() and len(word) > 1)\n",
    "    )\n",
    "    \n",
    "    # Enhanced negation detection\n",
    "    features['negation_count'] = df[text_column].str.count(r'NOT_')\n",
    "    features['but_count'] = df[text_column].str.count(r'BUT_CONTRAST|HOWEVER_CONTRAST|ALTHOUGH_CONTRAST')\n",
    "    features['has_negation'] = (features['negation_count'] > 0).astype(int)\n",
    "    features['has_contrast'] = (features['but_count'] > 0).astype(int)\n",
    "    \n",
    "    # Sentiment analysis\n",
    "    sentiments = df[text_column].apply(lambda x: TextBlob(str(x)).sentiment)\n",
    "    features['sentiment_polarity'] = sentiments.apply(lambda x: x.polarity)\n",
    "    features['sentiment_subjectivity'] = sentiments.apply(lambda x: x.subjectivity)\n",
    "    features['polarity_abs'] = features['sentiment_polarity'].abs()\n",
    "    features['polarity_squared'] = features['sentiment_polarity'] ** 2\n",
    "    \n",
    "    # Interaction features\n",
    "    features['negation_polarity_interaction'] = features['negation_count'] * features['sentiment_polarity']\n",
    "    features['contrast_polarity_interaction'] = features['but_count'] * features['sentiment_polarity']\n",
    "    \n",
    "    # Enhanced word lists\n",
    "    strong_positive = ['excellent', 'amazing', 'wonderful', 'perfect', 'awesome', \n",
    "                      'fantastic', 'outstanding', 'delicious', 'best', 'love',\n",
    "                      'great', 'superb', 'brilliant', 'incredible', 'phenomenal']\n",
    "    strong_negative = ['terrible', 'awful', 'horrible', 'disgusting', 'worst', \n",
    "                      'waste', 'disappointed', 'hate', 'bad', 'poor',\n",
    "                      'useless', 'pathetic', 'nasty', 'gross', 'dreadful']\n",
    "    moderate_positive = ['good', 'nice', 'fine', 'okay', 'decent', 'pleasant']\n",
    "    moderate_negative = ['mediocre', 'bland', 'boring', 'meh', 'average']\n",
    "    \n",
    "    features['strong_positive_count'] = df[text_column].apply(\n",
    "        lambda x: sum(1 for word in strong_positive if word in str(x).lower())\n",
    "    )\n",
    "    features['strong_negative_count'] = df[text_column].apply(\n",
    "        lambda x: sum(1 for word in strong_negative if word in str(x).lower())\n",
    "    )\n",
    "    features['moderate_positive_count'] = df[text_column].apply(\n",
    "        lambda x: sum(1 for word in moderate_positive if word in str(x).lower())\n",
    "    )\n",
    "    features['moderate_negative_count'] = df[text_column].apply(\n",
    "        lambda x: sum(1 for word in moderate_negative if word in str(x).lower())\n",
    "    )\n",
    "    \n",
    "    features['sentiment_word_score'] = (\n",
    "        (features['strong_positive_count'] * 2) + features['moderate_positive_count'] -\n",
    "        (features['strong_negative_count'] * 2) - features['moderate_negative_count']\n",
    "    )\n",
    "    \n",
    "    # Negation impact\n",
    "    features['negated_positive'] = features['negation_count'] * features['strong_positive_count']\n",
    "    features['negated_negative'] = features['negation_count'] * features['strong_negative_count']\n",
    "    \n",
    "    features = features.fillna(0)\n",
    "    return features\n",
    "\n",
    "# ========================================\n",
    "# LOAD AND PREPARE DATA\n",
    "# ========================================\n",
    "print(\"\\nüìÇ Loading training dataset...\")\n",
    "train_df = pd.read_csv('imbalanced_updated.csv')  # ‚Üê CHANGE THIS\n",
    "\n",
    "print(f\"Total available samples: {len(train_df)}\")\n",
    "\n",
    "# ========================================\n",
    "# PREPROCESS FIRST\n",
    "# ========================================\n",
    "print(\"\\nüìù Preprocessing ALL data first...\")\n",
    "train_df['cleaned_summary'] = train_df['Summary'].astype(str).apply(advanced_text_cleaning)\n",
    "train_df['word_count_temp'] = train_df['cleaned_summary'].str.split().str.len()\n",
    "\n",
    "# More lenient filtering to keep more samples\n",
    "print(f\"Before filtering: {len(train_df)} samples\")\n",
    "train_df_filtered = train_df[\n",
    "    (train_df['word_count_temp'] >= 2) &  # Changed from 3 to 2\n",
    "    (train_df['word_count_temp'] <= 200)  # Changed from 150 to 200\n",
    "].copy()\n",
    "train_df_filtered = train_df_filtered.drop('word_count_temp', axis=1)\n",
    "print(f\"After filtering: {len(train_df_filtered)} samples\")\n",
    "\n",
    "print(\"\\nClass distribution after filtering:\")\n",
    "print(train_df_filtered['Score'].value_counts().sort_index())\n",
    "\n",
    "# ========================================\n",
    "# SMARTER SAMPLING STRATEGY\n",
    "# ========================================\n",
    "print(\"\\nüìä Creating training dataset with improved sampling...\")\n",
    "\n",
    "# More balanced distribution to reduce class imbalance\n",
    "train_sample_sizes = {\n",
    "    1: 3000,   # 15% (increased from 10%)\n",
    "    2: 3500,   # 17.5% (increased from 15%)\n",
    "    3: 4500,   # 22.5% (decreased from 25%)\n",
    "    4: 5000,   # 25% (decreased from 30%)\n",
    "    5: 4000    # 20%\n",
    "}\n",
    "\n",
    "train_sampled_parts = []\n",
    "for score, n in train_sample_sizes.items():\n",
    "    subset = train_df_filtered[train_df_filtered['Score'] == score]\n",
    "    if len(subset) >= n:\n",
    "        subset = subset.sample(n=n, random_state=42)\n",
    "        print(f\"  Class {score}: Sampled {n} from {len(subset)} available\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è Class {score}: Only {len(subset)} samples available, using all\")\n",
    "        subset = subset.copy()\n",
    "    train_sampled_parts.append(subset)\n",
    "\n",
    "train_data = pd.concat(train_sampled_parts, ignore_index=True)\n",
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nüìä Final training distribution:\")\n",
    "print(train_data['Score'].value_counts().sort_index())\n",
    "print(f\"‚úÖ Total training samples: {len(train_data)}\")\n",
    "\n",
    "# ========================================\n",
    "# EXTRACT FEATURES\n",
    "# ========================================\n",
    "print(\"\\nüîß Extracting enhanced features...\")\n",
    "train_features = extract_enhanced_features(train_data, 'cleaned_summary')\n",
    "print(f\"  Extracted {train_features.shape[1]} features\")\n",
    "\n",
    "X_train_text = train_data['cleaned_summary']\n",
    "y_train = train_data['Score']\n",
    "\n",
    "# ========================================\n",
    "# IMPROVED VECTORIZATION\n",
    "# ========================================\n",
    "print(\"\\nüî§ Vectorizing text with improved parameters...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=8000,  # Increased from 6000\n",
    "    ngram_range=(1, 3),  # Added trigrams\n",
    "    min_df=3,  # More lenient\n",
    "    max_df=0.85,  # More lenient\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    norm='l2'\n",
    ")\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
    "\n",
    "print(\"üîó Combining features...\")\n",
    "scaler = StandardScaler(with_mean=False)  # Important for sparse matrices\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "\n",
    "X_train_combined = hstack([X_train_tfidf, train_features_scaled])\n",
    "print(f\"Training feature shape: {X_train_combined.shape}\")\n",
    "\n",
    "# ========================================\n",
    "# CALCULATE CLASS WEIGHTS\n",
    "# ========================================\n",
    "print(\"\\n‚öñÔ∏è  Calculating optimized class weights...\")\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# Smooth weights to avoid over-penalization\n",
    "max_weight = max(class_weight_dict.values())\n",
    "for k in class_weight_dict:\n",
    "    class_weight_dict[k] = min(class_weight_dict[k], max_weight * 0.8)\n",
    "\n",
    "print(\"Smoothed class weights:\")\n",
    "for class_label, weight in class_weight_dict.items():\n",
    "    count = (y_train == class_label).sum()\n",
    "    print(f\"  Class {class_label}: {weight:.3f} (n={count})\")\n",
    "\n",
    "# ========================================\n",
    "# TRAIN MULTIPLE MODELS\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING IMPROVED MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "models = {}\n",
    "cv_results = {}\n",
    "\n",
    "# Create scorer\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Cross-validation setup\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 1. Logistic Regression with optimized parameters\n",
    "print(\"\\n1Ô∏è‚É£  Training Logistic Regression (optimized)...\")\n",
    "lr_optimized = LogisticRegression(\n",
    "    C=1.0,  # Increased regularization strength\n",
    "    class_weight=class_weight_dict,\n",
    "    max_iter=3000,\n",
    "    random_state=42,\n",
    "    solver='saga',  # Better for large datasets\n",
    "    penalty='l2',\n",
    "    multi_class='multinomial'\n",
    ")\n",
    "\n",
    "print(\"   Performing cross-validation...\")\n",
    "cv_scores_lr = cross_val_score(\n",
    "    lr_optimized, X_train_combined, y_train,\n",
    "    cv=skf, scoring=f1_macro_scorer, n_jobs=-1\n",
    ")\n",
    "print(f\"   CV Macro F1: {cv_scores_lr.mean():.4f} (+/- {cv_scores_lr.std():.4f})\")\n",
    "\n",
    "lr_optimized.fit(X_train_combined, y_train)\n",
    "models['lr_optimized'] = lr_optimized\n",
    "cv_results['lr_optimized'] = cv_scores_lr.mean()\n",
    "\n",
    "# 2. Calibrated Logistic Regression\n",
    "print(\"\\n2Ô∏è‚É£  Training Calibrated LR...\")\n",
    "calibrated_lr = CalibratedClassifierCV(\n",
    "    lr_optimized,\n",
    "    method='sigmoid',  # Changed from isotonic\n",
    "    cv=3  # Reduced for speed\n",
    ")\n",
    "\n",
    "print(\"   Fitting calibrated model...\")\n",
    "calibrated_lr.fit(X_train_combined, y_train)\n",
    "\n",
    "print(\"   Performing cross-validation...\")\n",
    "cv_scores_cal = cross_val_score(\n",
    "    CalibratedClassifierCV(lr_optimized, method='sigmoid', cv=3),\n",
    "    X_train_combined, y_train,\n",
    "    cv=skf, scoring=f1_macro_scorer, n_jobs=-1\n",
    ")\n",
    "print(f\"   CV Macro F1: {cv_scores_cal.mean():.4f} (+/- {cv_scores_cal.std():.4f})\")\n",
    "\n",
    "models['lr_calibrated'] = calibrated_lr\n",
    "cv_results['lr_calibrated'] = cv_scores_cal.mean()\n",
    "\n",
    "# 3. Random Forest with optimized parameters\n",
    "print(\"\\n3Ô∏è‚É£  Training Random Forest (optimized)...\")\n",
    "rf_optimized = RandomForestClassifier(\n",
    "    n_estimators=300,  # Increased\n",
    "    max_depth=25,  # Slightly increased\n",
    "    min_samples_split=8,\n",
    "    min_samples_leaf=3,\n",
    "    class_weight=class_weight_dict,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    bootstrap=True,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "print(\"   Performing cross-validation...\")\n",
    "cv_scores_rf = cross_val_score(\n",
    "    rf_optimized, X_train_combined, y_train,\n",
    "    cv=skf, scoring=f1_macro_scorer, n_jobs=-1\n",
    ")\n",
    "print(f\"   CV Macro F1: {cv_scores_rf.mean():.4f} (+/- {cv_scores_rf.std():.4f})\")\n",
    "\n",
    "rf_optimized.fit(X_train_combined, y_train)\n",
    "print(f\"   OOB Score: {rf_optimized.oob_score_:.4f}\")\n",
    "models['rf_optimized'] = rf_optimized\n",
    "cv_results['rf_optimized'] = cv_scores_rf.mean()\n",
    "\n",
    "# 4. Gradient Boosting (NEW)\n",
    "print(\"\\n4Ô∏è‚É£  Training Gradient Boosting (NEW)...\")\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=7,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"   Performing cross-validation...\")\n",
    "cv_scores_gb = cross_val_score(\n",
    "    gb, X_train_combined, y_train,\n",
    "    cv=skf, scoring=f1_macro_scorer, n_jobs=-1\n",
    ")\n",
    "print(f\"   CV Macro F1: {cv_scores_gb.mean():.4f} (+/- {cv_scores_gb.std():.4f})\")\n",
    "\n",
    "gb.fit(X_train_combined, y_train)\n",
    "models['gradient_boosting'] = gb\n",
    "cv_results['gradient_boosting'] = cv_scores_gb.mean()\n",
    "\n",
    "# ========================================\n",
    "# SELECT BEST MODEL\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL SELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n{'Model':<25} {'CV Macro F1':<15} {'Std Dev':<10}\")\n",
    "print(\"-\" * 50)\n",
    "all_cv_scores = {\n",
    "    'lr_optimized': cv_scores_lr,\n",
    "    'lr_calibrated': cv_scores_cal,\n",
    "    'rf_optimized': cv_scores_rf,\n",
    "    'gradient_boosting': cv_scores_gb\n",
    "}\n",
    "\n",
    "for model_name, scores in all_cv_scores.items():\n",
    "    print(f\"{model_name:<25} {scores.mean():<15.4f} {scores.std():<10.4f}\")\n",
    "\n",
    "best_model_name = max(cv_results.items(), key=lambda x: x[1])[0]\n",
    "best_model = models[best_model_name]\n",
    "best_cv_score = cv_results[best_model_name]\n",
    "\n",
    "print(f\"\\n Model_B: {best_model_name}\")\n",
    "print(f\"   CV Macro F1: {best_cv_score:.4f}\")\n",
    "\n",
    "# Get training predictions for best model\n",
    "y_train_pred = best_model.predict(X_train_combined)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_f1_macro = f1_score(y_train, y_train_pred, average='macro')\n",
    "\n",
    "print(f\"   Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"   Training Macro F1: {train_f1_macro:.4f}\")\n",
    "\n",
    "# ========================================\n",
    "# SAVE EVERYTHING\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SAVING MODEL AND ARTIFACTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "with open('model_B.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(\"‚úÖ model_B.pkl\")\n",
    "\n",
    "with open('model_B_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "print(\"‚úÖ model_B_vectorizer.pkl\")\n",
    "\n",
    "with open('model_B_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"‚úÖ model_B_scaler.pkl\")\n",
    "\n",
    "metadata = {\n",
    "    'best_model_name': best_model_name,\n",
    "    'training_distribution': train_sample_sizes,\n",
    "    'train_samples': len(train_data),\n",
    "    'feature_names': list(train_features.columns),\n",
    "    'train_accuracy': train_accuracy,\n",
    "    'train_f1_macro': train_f1_macro,\n",
    "    'cv_f1_macro': best_cv_score,\n",
    "    'cv_f1_std': all_cv_scores[best_model_name].std(),\n",
    "    'class_weights': class_weight_dict,\n",
    "    'all_cv_results': {k: v for k, v in cv_results.items()},\n",
    "    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "with open('model_B_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "print(\"‚úÖ model_B_metadata.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ú® TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"   ‚Ä¢ Model: {best_model_name}\")\n",
    "print(f\"   ‚Ä¢ Training samples: {len(train_data)}\")\n",
    "print(f\"   ‚Ä¢ Features: {X_train_combined.shape[1]}\")\n",
    "print(f\"   ‚Ä¢ Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"   ‚Ä¢ Training Macro F1: {train_f1_macro:.4f}\")\n",
    "print(f\"   ‚Ä¢ CV Macro F1: {best_cv_score:.4f} (+/- {all_cv_scores[best_model_name].std():.4f})\")\n",
    "\n",
    "print(f\"\\n‚û°Ô∏è  Next: Run test_model.py with your test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9180349e",
   "metadata": {},
   "source": [
    "testing of model_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9620251b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TESTING GRADIENT BOOSTING ON IMBALANCED DATASET\n",
      "======================================================================\n",
      "\n",
      "üì¶ Loading trained Gradient Boosting model and artifacts...\n",
      "  ‚ùå ../../Models/model_A.pkl not found!\n",
      "\n",
      "‚ö†Ô∏è  Error: Missing required files\n",
      "     Please run train_balanced.py first!\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\x07'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 63\u001b[0m         loaded_artifacts[var_name] \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  ‚úÖ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '\\x07'."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "test_imbalanced.py\n",
    "==================\n",
    "Test Gradient Boosting model (trained on BALANCED data) against IMBALANCED test set\n",
    "Test distribution: Realistic imbalanced distribution (20,000 samples)\n",
    "\n",
    "Prerequisites:\n",
    "    - balanced_trained_model.pkl (Gradient Boosting)\n",
    "    - balanced_trained_vectorizer.pkl\n",
    "    - balanced_trained_scaler.pkl\n",
    "    - balanced_trained_metadata.pkl\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             accuracy_score, f1_score, roc_auc_score,\n",
    "                             precision_recall_fscore_support)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy.sparse import hstack\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTING GRADIENT BOOSTING ON IMBALANCED DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ========================================\n",
    "# CONFIGURATION\n",
    "# ========================================\n",
    "TEST_DATA_FILE = 'imbalanced_updated.csv'  # ‚Üê CHANGE THIS\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Imbalanced test distribution (20,000 total)\n",
    "TEST_DISTRIBUTION = {\n",
    "    1: 2000,   # 10% - Very negative (Minority)\n",
    "    2: 3000,   # 15% - Negative (Minority)\n",
    "    3: 5000,   # 25% - Neutral (Balanced)\n",
    "    4: 6000,   # 30% - Positive (Majority)\n",
    "    5: 4000    # 20% - Very positive (Balanced)\n",
    "}\n",
    "\n",
    "# ========================================\n",
    "# LOAD TRAINED ARTIFACTS\n",
    "# ========================================\n",
    "print(\"\\nüì¶ Loading trained Gradient Boosting model and artifacts...\")\n",
    "\n",
    "required_files = {\n",
    "    '../../Models/model_A.pkl': 'model',\n",
    "    '../../Models/model_A_vectorizer.pkl': 'vectorizer',\n",
    "    '../../Models/model_A_scaler.pkl': 'scaler',\n",
    "    '../../Models/model_A_metadata.pkl': 'metadata'\n",
    "}\n",
    "\n",
    "loaded_artifacts = {}\n",
    "\n",
    "for filename, var_name in required_files.items():\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            loaded_artifacts[var_name] = pickle.load(f)\n",
    "        print(f\"  ‚úÖ {filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ‚ùå {filename} not found!\")\n",
    "        print(f\"\\n‚ö†Ô∏è  Error: Missing required files\")\n",
    "        print(f\"     Please run train_balanced.py first!\")\n",
    "        exit(1)\n",
    "\n",
    "model = loaded_artifacts['model']\n",
    "vectorizer = loaded_artifacts['vectorizer']\n",
    "scaler = loaded_artifacts['scaler']\n",
    "metadata = loaded_artifacts['metadata']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL INFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Training Type: {metadata.get('training_type', 'BALANCED')}\")\n",
    "print(f\"Model: {metadata['best_model_name']}\")\n",
    "print(f\"Trained: {metadata.get('training_date', 'Unknown')}\")\n",
    "print(f\"Training samples: {metadata['train_samples']:,} (balanced)\")\n",
    "print(f\"Samples per class: {metadata.get('samples_per_class', 2000):,}\")\n",
    "print(f\"Training Accuracy: {metadata['train_accuracy']:.4f}\")\n",
    "print(f\"Training Macro F1: {metadata['train_f1_macro']:.4f}\")\n",
    "print(f\"CV Macro F1: {metadata['cv_f1_macro']:.4f} (+/- {metadata.get('cv_f1_std', 0):.4f})\")\n",
    "\n",
    "# ========================================\n",
    "# PREPROCESSING FUNCTIONS (MUST MATCH TRAINING)\n",
    "# ========================================\n",
    "def advanced_text_cleaning(text):\n",
    "    \"\"\"Enhanced text cleaning - MUST match training exactly\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    negation_words = ['not', 'no', 'never', 'neither', 'nobody', 'nothing', \n",
    "                      'nowhere', 'none', \"n't\", 'dont', 'wont', 'cant', 'shouldnt']\n",
    "    for word in negation_words:\n",
    "        text = re.sub(rf'\\b{word}\\b', f'NOT_{word}', text)\n",
    "    \n",
    "    text = text.replace(' but ', ' BUT_CONTRAST ')\n",
    "    text = text.replace(' however ', ' HOWEVER_CONTRAST ')\n",
    "    text = text.replace(' although ', ' ALTHOUGH_CONTRAST ')\n",
    "    \n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s!?._]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_enhanced_features(df, text_column):\n",
    "    \"\"\"Enhanced feature extraction - MUST match training exactly\"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    features['text_length'] = df[text_column].str.len()\n",
    "    features['word_count'] = df[text_column].str.split().str.len()\n",
    "    features['avg_word_length'] = features['text_length'] / (features['word_count'] + 1)\n",
    "    features['unique_word_ratio'] = df[text_column].apply(\n",
    "        lambda x: len(set(str(x).split())) / (len(str(x).split()) + 1)\n",
    "    )\n",
    "    \n",
    "    features['exclamation_count'] = df[text_column].str.count(r'!')\n",
    "    features['question_count'] = df[text_column].str.count(r'\\?')\n",
    "    features['period_count'] = df[text_column].str.count(r'\\.')\n",
    "    features['uppercase_ratio'] = df[text_column].str.count(r'[A-Z]') / (features['text_length'] + 1)\n",
    "    features['all_caps_words'] = df[text_column].apply(\n",
    "        lambda x: sum(1 for word in str(x).split() if word.isupper() and len(word) > 1)\n",
    "    )\n",
    "    \n",
    "    features['negation_count'] = df[text_column].str.count(r'NOT_')\n",
    "    features['but_count'] = df[text_column].str.count(r'BUT_CONTRAST|HOWEVER_CONTRAST|ALTHOUGH_CONTRAST')\n",
    "    features['has_negation'] = (features['negation_count'] > 0).astype(int)\n",
    "    features['has_contrast'] = (features['but_count'] > 0).astype(int)\n",
    "    \n",
    "    sentiments = df[text_column].apply(lambda x: TextBlob(str(x)).sentiment)\n",
    "    features['sentiment_polarity'] = sentiments.apply(lambda x: x.polarity)\n",
    "    features['sentiment_subjectivity'] = sentiments.apply(lambda x: x.subjectivity)\n",
    "    features['polarity_abs'] = features['sentiment_polarity'].abs()\n",
    "    features['polarity_squared'] = features['sentiment_polarity'] ** 2\n",
    "    \n",
    "    features['negation_polarity_interaction'] = features['negation_count'] * features['sentiment_polarity']\n",
    "    features['contrast_polarity_interaction'] = features['but_count'] * features['sentiment_polarity']\n",
    "    \n",
    "    strong_positive = ['excellent', 'amazing', 'wonderful', 'perfect', 'awesome', \n",
    "                      'fantastic', 'outstanding', 'delicious', 'best', 'love',\n",
    "                      'great', 'superb', 'brilliant', 'incredible', 'phenomenal']\n",
    "    strong_negative = ['terrible', 'awful', 'horrible', 'disgusting', 'worst', \n",
    "                      'waste', 'disappointed', 'hate', 'bad', 'poor',\n",
    "                      'useless', 'pathetic', 'nasty', 'gross', 'dreadful']\n",
    "    moderate_positive = ['good', 'nice', 'fine', 'okay', 'decent', 'pleasant']\n",
    "    moderate_negative = ['mediocre', 'bland', 'boring', 'meh', 'average']\n",
    "    \n",
    "    features['strong_positive_count'] = df[text_column].apply(\n",
    "        lambda x: sum(1 for word in strong_positive if word in str(x).lower())\n",
    "    )\n",
    "    features['strong_negative_count'] = df[text_column].apply(\n",
    "        lambda x: sum(1 for word in strong_negative if word in str(x).lower())\n",
    "    )\n",
    "    features['moderate_positive_count'] = df[text_column].apply(\n",
    "        lambda x: sum(1 for word in moderate_positive if word in str(x).lower())\n",
    "    )\n",
    "    features['moderate_negative_count'] = df[text_column].apply(\n",
    "        lambda x: sum(1 for word in moderate_negative if word in str(x).lower())\n",
    "    )\n",
    "    \n",
    "    features['sentiment_word_score'] = (\n",
    "        (features['strong_positive_count'] * 2) + features['moderate_positive_count'] -\n",
    "        (features['strong_negative_count'] * 2) - features['moderate_negative_count']\n",
    "    )\n",
    "    \n",
    "    features['negated_positive'] = features['negation_count'] * features['strong_positive_count']\n",
    "    features['negated_negative'] = features['negation_count'] * features['strong_negative_count']\n",
    "    \n",
    "    # Ensure features match training\n",
    "    expected_features = metadata['feature_names']\n",
    "    for feat in expected_features:\n",
    "        if feat not in features.columns:\n",
    "            features[feat] = 0\n",
    "    features = features[expected_features]\n",
    "    \n",
    "    features = features.fillna(0)\n",
    "    return features\n",
    "\n",
    "# ========================================\n",
    "# LOAD TEST DATA\n",
    "# ========================================\n",
    "print(f\"\\nüìÇ Loading test data from: {TEST_DATA_FILE}\")\n",
    "\n",
    "try:\n",
    "    test_df = pd.read_csv(TEST_DATA_FILE)\n",
    "    print(f\"‚úÖ Loaded {len(test_df):,} samples\")\n",
    "    print(f\"   Columns: {list(test_df.columns)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: File '{TEST_DATA_FILE}' not found!\")\n",
    "    print(\"   Please update TEST_DATA_FILE variable with correct path\")\n",
    "    exit(1)\n",
    "\n",
    "if 'Score' not in test_df.columns or 'Summary' not in test_df.columns:\n",
    "    print(\"‚ùå Error: Dataset must contain 'Score' and 'Summary' columns!\")\n",
    "    exit(1)\n",
    "\n",
    "# ========================================\n",
    "# PREPROCESS FIRST\n",
    "# ========================================\n",
    "print(\"\\nüìù Preprocessing ALL test data first...\")\n",
    "test_df['cleaned_summary'] = test_df['Summary'].astype(str).apply(advanced_text_cleaning)\n",
    "test_df['word_count_temp'] = test_df['cleaned_summary'].str.split().str.len()\n",
    "\n",
    "print(f\"Before filtering: {len(test_df):,} samples\")\n",
    "test_df_filtered = test_df[\n",
    "    (test_df['word_count_temp'] >= 2) &\n",
    "    (test_df['word_count_temp'] <= 200)\n",
    "].copy()\n",
    "test_df_filtered = test_df_filtered.drop('word_count_temp', axis=1)\n",
    "print(f\"After filtering: {len(test_df_filtered):,} samples\")\n",
    "\n",
    "print(\"\\nClass distribution after filtering:\")\n",
    "print(test_df_filtered['Score'].value_counts().sort_index())\n",
    "\n",
    "# ========================================\n",
    "# CREATE IMBALANCED TEST SET\n",
    "# ========================================\n",
    "print(f\"\\nüìä Creating IMBALANCED test dataset (20,000 samples)...\")\n",
    "\n",
    "test_sampled_parts = []\n",
    "for score, n in TEST_DISTRIBUTION.items():\n",
    "    subset = test_df_filtered[test_df_filtered['Score'] == score]\n",
    "    available = len(subset)\n",
    "    \n",
    "    if available >= n:\n",
    "        subset = subset.sample(n=n, random_state=RANDOM_SEED)\n",
    "        print(f\"  Class {score}: Sampled {n:,} from {available:,} available\")\n",
    "    else:\n",
    "        print(f\"  Class {score}: ‚ö†Ô∏è  Only {available:,} available (needed {n:,})\")\n",
    "        subset = subset.copy()\n",
    "    \n",
    "    test_sampled_parts.append(subset)\n",
    "\n",
    "test_data = pd.concat(test_sampled_parts, ignore_index=True)\n",
    "test_data = test_data.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nüìä Final test distribution (IMBALANCED):\")\n",
    "for score, count in test_data['Score'].value_counts().sort_index().items():\n",
    "    pct = count / len(test_data) * 100\n",
    "    class_type = \"Minority\" if pct < 15 else \"Majority\" if pct > 25 else \"Balanced\"\n",
    "    print(f\"  Class {score}: {count:,} ({pct:5.1f}%) - {class_type}\")\n",
    "print(f\"‚úÖ TOTAL: {len(test_data):,} samples\")\n",
    "\n",
    "# ========================================\n",
    "# EXTRACT FEATURES & TRANSFORM\n",
    "# ========================================\n",
    "print(\"\\nüîß Extracting enhanced features...\")\n",
    "test_features = extract_enhanced_features(test_data, 'cleaned_summary')\n",
    "print(f\"  Extracted {test_features.shape[1]} features\")\n",
    "\n",
    "X_test_text = test_data['cleaned_summary']\n",
    "y_test = test_data['Score']\n",
    "\n",
    "print(\"\\nüî§ Transforming test data...\")\n",
    "X_test_tfidf = vectorizer.transform(X_test_text)\n",
    "print(f\"  TF-IDF shape: {X_test_tfidf.shape}\")\n",
    "\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "X_test_combined = hstack([X_test_tfidf, test_features_scaled])\n",
    "print(f\"  Final feature shape: {X_test_combined.shape}\")\n",
    "\n",
    "# ========================================\n",
    "# PREDICTIONS\n",
    "# ========================================\n",
    "print(\"\\nüîÆ Making predictions with Gradient Boosting...\")\n",
    "y_pred = model.predict(X_test_combined)\n",
    "y_proba = model.predict_proba(X_test_combined)\n",
    "print(\"‚úÖ Predictions complete!\")\n",
    "\n",
    "# ========================================\n",
    "# EVALUATION\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_weighted_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "test_macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"\\nüìä Overall Metrics:\")\n",
    "print(f\"  Accuracy:    {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"  Weighted F1: {test_weighted_f1:.4f}\")\n",
    "print(f\"  Macro F1:    {test_macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(\"\\nüî¢ Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"     Predicted\")\n",
    "print(\"     1    2    3    4    5\")\n",
    "for i, row in enumerate(cm):\n",
    "    print(f\"{i+1}  {row}\")\n",
    "\n",
    "\n",
    "\n",
    "# ROC-AUC\n",
    "print(\"\\nüéØ ROC-AUC Scores:\")\n",
    "y_test_bin = label_binarize(y_test, classes=sorted(np.unique(y_test)))\n",
    "roc_auc_scores = {}\n",
    "\n",
    "for i, class_label in enumerate(sorted(np.unique(y_test))):\n",
    "    roc_auc_scores[class_label] = roc_auc_score(y_test_bin[:, i], y_proba[:, i])\n",
    "    print(f\"  Class {class_label}: {roc_auc_scores[class_label]:.3f}\")\n",
    "\n",
    "macro_roc_auc = np.mean(list(roc_auc_scores.values()))\n",
    "weighted_roc_auc = roc_auc_score(y_test_bin, y_proba, average='weighted')\n",
    "\n",
    "print(f\"\\n  Macro ROC-AUC:    {macro_roc_auc:.3f}\")\n",
    "print(f\"  Weighted ROC-AUC: {weighted_roc_auc:.3f}\")\n",
    "\n",
    "# ========================================\n",
    "# TRAINING VS TEST COMPARISON\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BALANCED TRAINING vs IMBALANCED TEST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n{'Metric':<20} {'Train (Bal)':<15} {'CV (Bal)':<15} {'Test (Imb)':<15}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Accuracy':<20} {metadata['train_accuracy']:<15.4f} \"\n",
    "      f\"{'N/A':<15} {test_accuracy:<15.4f}\")\n",
    "print(f\"{'Macro F1':<20} {metadata['train_f1_macro']:<15.4f} \"\n",
    "      f\"{metadata['cv_f1_macro']:<15.4f} {test_macro_f1:<15.4f}\")\n",
    "\n",
    "cv_gap = abs(test_macro_f1 - metadata['cv_f1_macro'])\n",
    "train_gap = abs(test_macro_f1 - metadata['train_f1_macro'])\n",
    "\n",
    "print(f\"\\nGeneralization Analysis:\")\n",
    "print(f\"  CV ‚Üí Test gap:    {cv_gap:.4f}\")\n",
    "print(f\"  Train ‚Üí Test gap: {train_gap:.4f}\")\n",
    "\n",
    "if cv_gap < 0.03:\n",
    "    status = \"‚úÖ Excellent! Model handles imbalanced data very well\"\n",
    "elif cv_gap < 0.06:\n",
    "    status = \"‚úì Good generalization to imbalanced data\"\n",
    "elif cv_gap < 0.10:\n",
    "    status = \"‚óã Acceptable - some performance drop on imbalanced data\"\n",
    "else:\n",
    "    status = \"‚ö†Ô∏è  Significant drop - model struggles with imbalanced distribution\"\n",
    "print(f\"  Status: {status}\")\n",
    "\n",
    "# ========================================\n",
    "# IMBALANCE IMPACT ANALYSIS\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"IMBALANCE IMPACT ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nPerformance by Class Frequency:\")\n",
    "print(f\"{'Class':<8} {'% of Data':<12} {'F1 Score':<12} {'Error Rate':<12} {'Status':<15}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for i in range(5):\n",
    "    class_label = i + 1\n",
    "    class_pct = (support[i] / len(test_data)) * 100\n",
    "    class_f1 = f1[i]\n",
    "    class_errors = (y_test == class_label).sum() - (cm[i, i])\n",
    "    class_total = (y_test == class_label).sum()\n",
    "    error_rate = (class_errors / class_total) * 100 if class_total > 0 else 0\n",
    "    \n",
    "    if class_pct < 15:\n",
    "        status = \"Underrep\"\n",
    "    elif class_pct > 25:\n",
    "        status = \"Overrep\"\n",
    "    else:\n",
    "        status = \"Balanced\"\n",
    "    \n",
    "    print(f\"{class_label:<8} {class_pct:<12.1f} {class_f1:<12.3f} {error_rate:<12.1f} {status:<15}\")\n",
    "\n",
    "# Group analysis\n",
    "minority_indices = [i for i in range(5) if (support[i] / len(test_data)) < 0.15]\n",
    "majority_indices = [i for i in range(5) if (support[i] / len(test_data)) > 0.25]\n",
    "\n",
    "print(\"\\nGrouped Performance:\")\n",
    "if minority_indices:\n",
    "    minority_f1 = np.mean([f1[i] for i in minority_indices])\n",
    "    minority_classes_str = ', '.join([str(i+1) for i in minority_indices])\n",
    "    print(f\"  Minority classes ({minority_classes_str}): F1 = {minority_f1:.3f}\")\n",
    "else:\n",
    "    minority_f1 = None\n",
    "    print(f\"  Minority classes: None\")\n",
    "\n",
    "if majority_indices:\n",
    "    majority_f1 = np.mean([f1[i] for i in majority_indices])\n",
    "    majority_classes_str = ', '.join([str(i+1) for i in majority_indices])\n",
    "    print(f\"  Majority classes ({majority_classes_str}): F1 = {majority_f1:.3f}\")\n",
    "else:\n",
    "    majority_f1 = None\n",
    "    print(f\"  Majority classes: None\")\n",
    "\n",
    "if minority_f1 is not None and majority_f1 is not None:\n",
    "    gap = abs(minority_f1 - majority_f1)\n",
    "    print(f\"  Performance gap:  {gap:.3f}\")\n",
    "    \n",
    "    if gap < 0.08:\n",
    "        print(\"  ‚Üí ‚úÖ Excellent! Model handles class imbalance very well\")\n",
    "    elif gap < 0.12:\n",
    "        print(\"  ‚Üí ‚úì Good - Reasonable performance across imbalanced classes\")\n",
    "    elif gap < 0.18:\n",
    "        print(\"  ‚Üí ‚óã Acceptable - Some bias toward majority classes\")\n",
    "    else:\n",
    "        print(\"  ‚Üí ‚ö†Ô∏è  Significant bias toward majority classes detected\")\n",
    "\n",
    "# ========================================\n",
    "# ERROR ANALYSIS\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ERROR ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Summary': test_data['Summary'],\n",
    "    'True_Score': y_test,\n",
    "    'Predicted_Score': y_pred,\n",
    "    'Correct': y_test == y_pred,\n",
    "    'Error_Magnitude': abs(y_test - y_pred)\n",
    "})\n",
    "\n",
    "for i in range(1, 6):\n",
    "    results_df[f'Prob_Class_{i}'] = y_proba[:, i-1]\n",
    "results_df['Confidence'] = [y_proba[i, pred-1] for i, pred in enumerate(y_pred)]\n",
    "\n",
    "print(\"\\nError Distribution:\")\n",
    "for error in range(5):\n",
    "    count = (results_df['Error_Magnitude'] == error).sum()\n",
    "    if count > 0:\n",
    "        pct = count / len(results_df) * 100\n",
    "        label = \"Correct\" if error == 0 else f\"Off by {error}\"\n",
    "        print(f\"  {label:<15} {count:5,} ({pct:5.1f}%)\")\n",
    "\n",
    "# Average error magnitude\n",
    "avg_error = results_df['Error_Magnitude'].mean()\n",
    "print(f\"\\n  Average error magnitude: {avg_error:.3f}\")\n",
    "\n",
    "# Worst predictions\n",
    "print(\"\\n‚ùå Top 5 Worst Predictions (Error = 4):\")\n",
    "worst = results_df[results_df['Error_Magnitude'] == 4].head(5)\n",
    "if len(worst) > 0:\n",
    "    for idx, (_, row) in enumerate(worst.iterrows(), 1):\n",
    "        summary = row['Summary'][:65] + '...' if len(row['Summary']) > 65 else row['Summary']\n",
    "        print(f\"\\n{idx}. {summary}\")\n",
    "        print(f\"   True: {row['True_Score']} ‚Üí Predicted: {row['Predicted_Score']} \"\n",
    "              f\"(confidence: {row['Confidence']:.3f})\")\n",
    "else:\n",
    "    print(\"  (No errors of magnitude 4)\")\n",
    "\n",
    "# Best predictions\n",
    "print(\"\\n‚úÖ Top 3 Best Predictions (High Confidence):\")\n",
    "correct = results_df[results_df['Correct'] == True]\n",
    "if len(correct) > 0:\n",
    "    best = correct.nlargest(3, 'Confidence')\n",
    "    for idx, (_, row) in enumerate(best.iterrows(), 1):\n",
    "        summary = row['Summary'][:65] + '...' if len(row['Summary']) > 65 else row['Summary']\n",
    "        print(f\"\\n{idx}. {summary}\")\n",
    "        print(f\"   Score: {row['Predicted_Score']}, Confidence: {row['Confidence']:.3f}\")\n",
    "\n",
    "# Most common confusions\n",
    "print(\"\\nüìä Top 10 Most Common Confusions:\")\n",
    "confusion_pairs = []\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            confusion_pairs.append((i+1, j+1, cm[i, j]))\n",
    "\n",
    "confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "for true_class, pred_class, count in confusion_pairs[:10]:\n",
    "    pct = count / cm[true_class-1, :].sum() * 100 if cm[true_class-1, :].sum() > 0 else 0\n",
    "    print(f\"  Class {true_class} ‚Üí {pred_class}: {count:4,} ({pct:5.1f}%)\")\n",
    "\n",
    "# ========================================\n",
    "# SAVE RESULTS\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results_df.to_csv('model_A_predictions.csv', index=False)\n",
    "print(\"‚úÖ model_A_predictions.csv\")\n",
    "\n",
    "test_results = {\n",
    "    'model_type': 'gradient_boosting',\n",
    "    'test_type': 'IMBALANCED',\n",
    "    'test_distribution': TEST_DISTRIBUTION,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'test_weighted_f1': test_weighted_f1,\n",
    "    'test_macro_f1': test_macro_f1,\n",
    "    'test_macro_roc_auc': macro_roc_auc,\n",
    "    'test_weighted_roc_auc': weighted_roc_auc,\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'per_class_f1': f1.tolist(),\n",
    "    'per_class_precision': precision.tolist(),\n",
    "    'per_class_recall': recall.tolist(),\n",
    "    'per_class_support': support.tolist(),\n",
    "    'roc_auc_per_class': roc_auc_scores,\n",
    "    'cv_vs_test_gap': cv_gap,\n",
    "    'train_vs_test_gap': train_gap,\n",
    "    'minority_f1': minority_f1,\n",
    "    'majority_f1': majority_f1,\n",
    "    'avg_error_magnitude': avg_error,\n",
    "    'training_metadata': metadata,\n",
    "    'test_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "with open('model_A_results.pkl', 'wb') as f:\n",
    "    pickle.dump(test_results, f)\n",
    "print(\"‚úÖ model_A_results.pkl\")\n",
    "\n",
    "# ========================================\n",
    "# FINAL SUMMARY\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ú® TESTING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Experiment Summary:\")\n",
    "print(f\"   Training: BALANCED (2,000 per class ‚Üí 10,000 total)\")\n",
    "print(f\"   Testing:  IMBALANCED (10-30% per class ‚Üí 20,000 total)\")\n",
    "print(f\"   Model:    {metadata['best_model_name']}\")\n",
    "\n",
    "print(f\"\\nüìà Performance Metrics:\")\n",
    "print(f\"   Test Accuracy:    {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"   Test Macro F1:    {test_macro_f1:.4f}\")\n",
    "print(f\"   Test Weighted F1: {test_weighted_f1:.4f}\")\n",
    "print(f\"   Macro ROC-AUC:    {macro_roc_auc:.3f}\")\n",
    "\n",
    "print(f\"\\nüîÑ Generalization:\")\n",
    "print(f\"   CV Macro F1:      {metadata['cv_f1_macro']:.4f}\")\n",
    "print(f\"   CV ‚Üí Test gap:    {cv_gap:.4f}\")\n",
    "\n",
    "if minority_f1 is not None and majority_f1 is not None:\n",
    "    print(f\"\\n‚öñÔ∏è  Class Balance:\")\n",
    "    print(f\"   Minority F1:      {minority_f1:.3f}\")\n",
    "    print(f\"   Majority F1:      {majority_f1:.3f}\")\n",
    "    print(f\"   Performance gap:  {abs(minority_f1 - majority_f1):.3f}\")\n",
    "\n",
    "print(f\"\\nüéØ Overall Assessment:\")\n",
    "if test_macro_f1 >= 0.48:\n",
    "    assessment = \"‚úÖ EXCELLENT\"\n",
    "    note = \"Model handles imbalanced data very well!\"\n",
    "elif test_macro_f1 >= 0.45:\n",
    "    assessment = \"‚úì GOOD\"\n",
    "    note = \"Solid performance on imbalanced distribution\"\n",
    "elif test_macro_f1 >= 0.42:\n",
    "    assessment = \"‚óã ACCEPTABLE\"\n",
    "    note = \"Reasonable performance despite imbalance\"\n",
    "else:\n",
    "    assessment = \"‚ö†Ô∏è  NEEDS IMPROVEMENT\"\n",
    "    note = \"Model struggles with imbalanced distribution\"\n",
    "\n",
    "print(f\"   {assessment}\")\n",
    "print(f\"   {note}\")\n",
    "\n",
    "print(f\"\\nüí° Key Insights:\")\n",
    "if cv_gap < 0.05:\n",
    "    print(f\"   ‚úÖ Minimal performance drop from balanced to imbalanced data\")\n",
    "    print(f\"   ‚úÖ Training on balanced data generalizes excellently\")\n",
    "\n",
    "if minority_f1 is not None and majority_f1 is not None:\n",
    "    if abs(minority_f1 - majority_f1) < 0.10:\n",
    "        print(f\"   ‚úÖ Fair predictions across minority and majority classes\")\n",
    "    elif abs(minority_f1 - majority_f1) < 0.15:\n",
    "        print(f\"   ‚úì Reasonable balance between minority and majority classes\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Some bias toward majority classes detected\")\n",
    "\n",
    "# Check worst performing class\n",
    "worst_f1_idx = np.argmin(f1)\n",
    "worst_f1_score = f1[worst_f1_idx]\n",
    "worst_class = worst_f1_idx + 1\n",
    "if worst_f1_score < 0.40:\n",
    "    class_pct = (support[worst_f1_idx] / len(test_data)) * 100\n",
    "    print(f\"   ‚ö†Ô∏è  Class {worst_class} underperforming (F1={worst_f1_score:.3f}, {class_pct:.1f}% of data)\")\n",
    "\n",
    "print(f\"\\nüì¶ Saved Files:\")\n",
    "print(f\"   ‚Ä¢ model_A_predictions.csv - Detailed predictions\")\n",
    "print(f\"   ‚Ä¢ model_A_results.pkl - Complete evaluation metrics\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Experiment: Balanced Training ‚Üí Imbalanced Testing Complete!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3ac86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
